---
title: ML Reproducibility Challenge 2023
type: book # Do not modify.
toc: false
headless: true
---

Welcome to the ML Reproducibility Challenge 2023 (**MLRC 2023**). This is the
seventh edition of the event
([v1](https://www.cs.mcgill.ca/~jpineau/ICLR2018-ReproducibilityChallenge.html),
[v2](https://www.cs.mcgill.ca/~jpineau/ICLR2019-ReproducibilityChallenge.html),
[v3](https://reproducibility-challenge.github.io/neurips2019/),
[v4](https://paperswithcode.com/rc2020),
[v5](https://paperswithcode.com/rc2021),
[v6](https://paperswithcode.com/rc2022)). The primary goal of this event is to
encourage the publishing and sharing of scientific results that are reliable and
reproducible. In support of this, the objective of this challenge is to
investigate reproducibility of papers accepted for publication at top
conferences by inviting members of the community at large to select a paper, and
verify the empirical results and claims in the paper by reproducing the
computational experiments, either via a new implementation or using code/data or
other information provided by the authors.

## Final decisions for MLRC 2023

We are now releasing the final list of decisions for MLRC 2023. This list
includes the previous partial list published on July 5th, 2024. We have given
additional time to TMLR to complete the reviews, however it is unfortunate that
few papers are still awaiting a decision due to unresponsive Action Editors from
TMLR. As we need to wrap up this edition, we are proceeding with the final list
of 22 accepted papers. Congratulations to all!

- Ana-Maria Vasilcoiu, Batu Helvacioğlu, Thies Kersten, Thijs Stessen;
  _GNNInterpreter: A probabilistic generative model-level explanation for Graph
  Neural Networks_, [OpenReview](https://openreview.net/forum?id=8cYcR23WUo)
- Miklos Hamar, Matey Krastev, Kristiyan Hristov, David Beglou; _Explaining
  Temporal Graph Models through an Explorer-Navigator Framework_,
  [OpenReview](https://openreview.net/forum?id=FI1XvwpchC)
- Clio Feng, Colin Bot, Bart den Boef, Bart Aaldering; _Reproducibility Study of
  "Explaining RL Decisions with Trajectories"_,
  [OpenReview](https://openreview.net/forum?id=JQoWmeNaC2)
- Ethan Harvey, Mikhail Petrov, Michael C. Hughes; _Transfer Learning with
  Informative Priors: Simple Baselines Better than Previously Reported_,
  [OpenReview](https://openreview.net/forum?id=BbvSU02jLg)
- Gijs de Jong,Macha Meijer,Derck W.E. Prinzhorn,Harold Ruiter; _Reproducibility
  study of FairAC_, [OpenReview](https://openreview.net/forum?id=ccDi5jtSF7)
- Nesta Midavaine, Gregory Hok Tjoan Go, Diego Canez, Ioana Simion, Satchit
  Chatterji; _On the Reproducibility of Post-Hoc Concept Bottleneck Models_;
  [OpenReview](https://openreview.net/forum?id=8UfhCZjOV7)
- Jiapeng Fan, Paulius Skaigiris, Luke Cadigan, Sebastian Uriel Arias;
  _Reproducibility Study of "Learning Perturbations to Explain Time Series
  Predictions"_, [OpenReview](https://openreview.net/forum?id=fCNqD2IuoD)
- Karim Ahmed Abdel Sadek, Matteo Nulli, Joan Velja, Jort Vincenti; _Explaining
  RL Decisions with Trajectories’: A Reproducibility Study_,
  [OpenReview](https://openreview.net/forum?id=QdeBbK5CSh)
- Markus Semmler, Miguel de Benito Delgado; _Classwise-Shapley values for data
  valuation_ [OpenReview](https://openreview.net/forum?id=srFEYJkqD7)
- Abdel Sadek Karim Ahmed, Nulli Matteo, Velja Joan, Vincenti Jort; _Explaining
  RL Decisions with Trajectories: A Reproducibility Study_,
  [OpenReview](https://openreview.net/forum?id=QdeBbK5CSh)
- Daniel Gallo Fernández, Răzvan-Andrei Matișan, Alejandro Monroy Muñoz, Janusz
  Partyka; _Reproducibility Study of "ITI-GEN: Inclusive Text-to-Image
  Generation"_ [OpenReview](https://openreview.net/forum?id=d3Vj360Wi2)
- Kacper Bartosik, Eren Kocadag, Vincent Loos, Lucas Ponticelli;
  _Reproducibility study of "Robust Fair Clustering: A Novel Fairness Attack and
  Defense Framework"_, [OpenReview](https://openreview.net/forum?id=Xu1sEPhjqH)
- Barath Chandran C; _CUDA: Curriculum of Data Augmentation for Long‐Tailed
  Recognition_, [OpenReview](https://openreview.net/forum?id=Wm6d44I8St)
- Kacper Bartosik, Eren Kocadag, Vincent Loos, Lucas Ponticelli;
  _Reproducibility study of "Robust Fair Clustering: A Novel Fairness Attack and
  Defense Framework"_, [OpenReview](https://openreview.net/forum?id=Xu1sEPhjqH)
- Christina Isaicu, Jesse Wonnink, Andreas Berentzen, Helia Ghasemi;
  _Reproducibility Study of “Explaining Temporal Graph Models Through an
  Explorer-Navigator Framework"_,
  [OpenReview](https://openreview.net/forum?id=9M2XqvH2SB)
- Iason Skylitsis, Zheng Feng, Idries Nasim, Camille Niessink; _Reproducibility
  Study of "Robust Fair Clustering: A Novel Fairness Attack and Defense
  Framework"_, [OpenReview](https://openreview.net/forum?id=H1hLNjwrGy)
- Fatemeh Nourilenjan Nokabadi, Jean-Francois Lalonde, Christian Gagné;
  _Reproducibility Study on Adversarial Attacks Against Robust Transformer
  Trackers_, [OpenReview](https://openreview.net/forum?id=FEEKR0Vl9s)
- Luan Fletcher, Robert van der Klis, Martin Sedlacek, Stefan Vasilev, Christos
  Athanasiadis; _Reproducibility study of “LICO: Explainable Models with
  Language-Image Consistency"_,
  [OpenReview](https://openreview.net/forum?id=Mf1H8X5DVb)
- Wouter Bant, Ádám Divák, Jasper Eppink, Floris Six Dijkstra; _On the
  Reproducibility of: "Learning Perturbations to Explain Time Series
  Predictions"_, [OpenReview](https://openreview.net/forum?id=nPZgtpfgIx)
- Berkay Chakar,Amina Izbassar,Mina Janićijević,Jakub Tomaszewski;
  _Reproducibility Study: Equal Improvability: A New Fairness Notion Considering
  the Long-Term Impact_,
  [OpenReview](https://openreview.net/forum?id=Yj8fUQGXXL)
- Oliver Bentham, Nathan Stringham, Ana Marasović; _Chain-of-Thought
  Unfaithfulness as Disguised Accuracy_,
  [OpenReview](https://openreview.net/forum?id=ydcrP55u2e)
- Shivank Garg, Manyana Tiwari; _Unmasking the Veil: An Investigation into
  Concept Ablation for Privacy and Copyright Protection in Images_
  [OpenReview](https://openreview.net/forum?id=TYYApLzjaQ)

If you are an author of the below mentioned papers and have not
[submitted the form](https://forms.gle/JJ28rLwBSxMriyE89) with the camera ready
items, please consider doing so at the earliest. We will reach out to the
accepted authors soon with the next steps. We will also announce the best paper
awards and share details on the logistics of NeurIPS poster session in the
coming weeks.

## An update on decisions

_July 5th, 2024_

We initially communicated to have all decisions of MLRC 2023 out by 31st of
May, 2024. Unfortunately, several submissions are still under review at TMLR,
and we are waiting for the final decisions to trickle in. Overall, MLRC 2023 had
46 valid submissions, out of which we have recieved decisions on 61% of them. We
are in touch with TMLR to expedite the process of decisions for the remaining
submissions - we expect all decisions to come in by the next couple of weeks.

Until then, we are happy to announce the (partial) list of accepted papers.
Congratulations to all :tada:! If you are an author of the below mentioned
papers and have not [submitted the form](https://forms.gle/JJ28rLwBSxMriyE89)
with the camera ready items, please consider doing so at the earliest. We will
reach out to the accepted authors soon with the next steps.

_(partial paper list removed as we release the final list above)_

## [Deprecated] Call For Papers

We invite contributions from academics, practitioners and industry researchers
of the ML community to submit novel and insightful reproducibility studies.
Please read our [blog post](/blog/announcing_mlrc2023/) regarding our
retrospectives of running the challenge and the future roadmap. We are happy to
announce the formal partnership with
[Transactions of Machine Learning Research (TMLR)](https://jmlr.org/tmlr/)
journal. The challenge goes live on **October 23, 2023**.

We recommend you choose any paper(s) published in the 2023 calendar year from
the top conferences and journals ([NeurIPS](https://neurips.cc/),
[ICML](https://icml.cc/), [ICLR](https://iclr.cc/),
[ACL](https://2023.aclweb.org/), [EMNLP](https://2023.emnlp.org/),
[ICCV](https://iccv2023.thecvf.com/),
[CVPR](https://cvpr2023.thecvf.com/Conferences/2023),
[TMLR](https://jmlr.org/tmlr/), [JMLR](https://jmlr.org/),
[TACL](https://transacl.org/index.php/tacl)) to run your reproducibility study
on.

{{< figure src="uploads/mlrc.drawio.svg" class="mlrc_dark" >}}

{{< figure src="uploads/mlrc.light.drawio.svg" class="mlrc_light" >}}

In order for your paper to be submitted and presented at MLRC 2023, it first
needs to be **accepted and published** at TMLR. While TMLR aims to follow a
2-months timeline to complete the review process of its regular submissions,
this timeline is not guaranteed. If you haven’t already, we therefore recommend
submitting your original paper to TMLR by **February 16th, 2024**, that is a
little over 3 months in advance of the MLRC publication announcement date.

## Key Dates

- Challenge goes live: October 23, 2023
- Deadline to share your **intent to submit** a TMLR paper to MLRC: **February
  16th, 2024** at the following form: **https://forms.gle/JJ28rLwBSxMriyE89**.
  This form requires that you provide a link to your TMLR submission. Once it
  gets accepted (if it isn’t already), you should then update the same form with
  your paper camera ready details. Your accepted TMLR paper will finally undergo
  a light AC review to verify MLRC compatibility.
- We aim to announce the accepted papers by ~~**May 31st, 2024**~~ **July 17th,
  2024**, pending decisions of all papers.

## Contact Information

- For query regarding MLRC 2023, mail us at:
  [mlrc-2023@googlegroups.com](mailto:mlrc-2023@googlegroups.com).
- For general queries, media, sponsorship, partnership requests, mail us at
  [reproducibility.challenge@gmail.com](reproducibility.challenge@gmail.com).
